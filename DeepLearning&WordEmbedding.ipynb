{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c122e2-ff2a-466e-8178-9001b31c5799",
   "metadata": {},
   "outputs": [],
   "source": [
    "©Liu Xiaoquan Ace,Assistant Professor,HKCHC   #Word embedding modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5fc55fa-094e-47f4-bc8b-da51e39f1fc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====================================================================================================\n",
      "First 10 rows:\n",
      "====================================================================================================\n",
      "   stkcd  accper          name  relid       grantno      patentee  \\\n",
      "0      1    2019    平安银行股份有限公司      0  CN305956746S    平安银行股份有限公司   \n",
      "1      1    2020    平安银行股份有限公司      0  CN212516570U    平安银行股份有限公司   \n",
      "2      1    2010  深圳发展银行股份有限公司      0  CN301426805S  深圳发展银行股份有限公司   \n",
      "3      1    2013    平安银行股份有限公司      0  CN103139210B    平安银行股份有限公司   \n",
      "4      1    2016    平安银行股份有限公司      0  CN304061944S    平安银行股份有限公司   \n",
      "5      1    2016    平安银行股份有限公司      0  CN304061945S    平安银行股份有限公司   \n",
      "6      1    2016    平安银行股份有限公司      0  CN304061946S    平安银行股份有限公司   \n",
      "7      1    2016    平安银行股份有限公司      0  CN304065945S    平安银行股份有限公司   \n",
      "8      1    2016    平安银行股份有限公司      0  CN304065946S    平安银行股份有限公司   \n",
      "9      1    2016    平安银行股份有限公司      0  CN304065947S    平安银行股份有限公司   \n",
      "\n",
      "         applino         patentname  \\\n",
      "0  2019305565562  手机的业绩数据分析显示图形用户界面   \n",
      "1  2020215432865             一种录音胸卡   \n",
      "2  2010301942648            信用卡(爽卡)   \n",
      "3  2013100478413           一种安全认证方法   \n",
      "4  2016303943680      用于智能终端的图形用户界面   \n",
      "5  2016303943727      用于智能终端的图形用户界面   \n",
      "6  2016303946636      用于智能终端的图形用户界面   \n",
      "7  2016303943731      用于智能终端的图形用户界面   \n",
      "8  2016303946621      用于智能终端的图形用户界面   \n",
      "9  2016303946674      用于智能终端的图形用户界面   \n",
      "\n",
      "                                             classno     appdate  \\\n",
      "0                                14-03(12);14-04(12)  2019-10-12   \n",
      "1                                G11C7/16(2006.01)I;  2020-07-29   \n",
      "2                                              19-08  2010-06-02   \n",
      "3  H04L29/06(2006.01)I;H04L9/32(2006.01)I;G06Q40/...  2013-02-06   \n",
      "4                                14-03(10);14-04(10)  2016-08-16   \n",
      "5                                14-03(10);14-04(10)  2016-08-16   \n",
      "6                                14-03(10);14-04(10)  2016-08-16   \n",
      "7                                14-03(10);14-04(10)  2016-08-16   \n",
      "8                                14-03(10);14-04(10)  2016-08-16   \n",
      "9                                14-03(10);14-04(10)  2016-08-16   \n",
      "\n",
      "         sameno  agent               agency  apppubdate grantpubdate  \\\n",
      "0           NaN     刘欣     广州华进联合专利商标代理有限公司         NaN   2020-07-31   \n",
      "1           NaN    谭果林  深圳众鼎专利商标代理事务所(普通合伙)         NaN   2021-02-09   \n",
      "2           NaN    李新林           深圳市精英专利事务所         NaN   2010-12-29   \n",
      "3  CN103139210A    李新林           深圳市精英专利事务所  2013-06-05   2016-09-14   \n",
      "4           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-01   \n",
      "5           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-01   \n",
      "6           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-01   \n",
      "7           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-08   \n",
      "8           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-08   \n",
      "9           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-08   \n",
      "\n",
      "                  inventor type  \\\n",
      "0                      徐继腾    D   \n",
      "1  王晟宇;张舒婷;赖众程;何利斌;杨念慈;高洪喜    U   \n",
      "2                  徐义龙;彭小军    D   \n",
      "3       张元良;李耀星;李恒;廖小荣;黄劲宾    I   \n",
      "4  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "5  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "6  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "7  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "8  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "9  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "\n",
      "                                         explanation  \\\n",
      "0  1.本外观设计产品的名称：手机的业绩数据分析显示图形用户界面。2.本外观设计产品的用途：本外...   \n",
      "1  本实用新型公开了一种录音胸卡，应用于录音技术领域，用于解决现有的录音设备录音效果受外界噪音影...   \n",
      "2  1.本设计产品名称为“信用卡(爽卡)”；2.本产品是一种银行储蓄卡；3.设计要点在于本产品的...   \n",
      "3  本发明公开一种安全认证方法，其包括以下步骤：S10，申请移动安全认证；S20，将移动通讯设备...   \n",
      "4  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "5  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "6  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "7  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "8  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "9  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "\n",
      "           applicantaddress  applicantemail  \n",
      "0        广东省深圳市罗湖区深南东路5047号        518021.0  \n",
      "1        广东省深圳市罗湖区深南东路5047号        518000.0  \n",
      "2        广东省深圳市罗湖区深南东路5047号        518000.0  \n",
      "3        广东省深圳市罗湖区深南东路5047号        518000.0  \n",
      "4  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "5  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "6  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "7  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "8  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "9  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "\n",
      "====================================================================================================\n",
      "Basic Data Information:\n",
      "====================================================================================================\n",
      "Data shape: 3166975 rows × 20 columns\n",
      "\n",
      "Column list:\n",
      "1. stkcd\n",
      "2. accper\n",
      "3. name\n",
      "4. relid\n",
      "5. grantno\n",
      "6. patentee\n",
      "7. applino\n",
      "8. patentname\n",
      "9. classno\n",
      "10. appdate\n",
      "11. sameno\n",
      "12. agent\n",
      "13. agency\n",
      "14. apppubdate\n",
      "15. grantpubdate\n",
      "16. inventor\n",
      "17. type\n",
      "18. explanation\n",
      "19. applicantaddress\n",
      "20. applicantemail\n",
      "\n",
      "====================================================================================================\n",
      "Detailed Data Structure:\n",
      "====================================================================================================\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3166975 entries, 0 to 3166974\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   stkcd             int64  \n",
      " 1   accper            int64  \n",
      " 2   name              object \n",
      " 3   relid             int64  \n",
      " 4   grantno           object \n",
      " 5   patentee          object \n",
      " 6   applino           object \n",
      " 7   patentname        object \n",
      " 8   classno           object \n",
      " 9   appdate           object \n",
      " 10  sameno            object \n",
      " 11  agent             object \n",
      " 12  agency            object \n",
      " 13  apppubdate        object \n",
      " 14  grantpubdate      object \n",
      " 15  inventor          object \n",
      " 16  type              object \n",
      " 17  explanation       object \n",
      " 18  applicantaddress  object \n",
      " 19  applicantemail    float64\n",
      "dtypes: float64(1), int64(3), object(16)\n",
      "memory usage: 483.2+ MB\n",
      "\n",
      "====================================================================================================\n",
      "Descriptive Statistics for Numerical Variables:\n",
      "====================================================================================================\n",
      "              stkcd        accper         relid  applicantemail\n",
      "count  3.166975e+06  3.166975e+06  3.166975e+06    3.160557e+06\n",
      "mean   3.222726e+05  2.017634e+03  7.702953e-01    3.353240e+05\n",
      "std    2.883311e+05  4.127507e+00  8.192447e-01    1.747803e+05\n",
      "min    1.000000e+00  2.000000e+03  0.000000e+00    1.000000e+04\n",
      "25%    2.075000e+03  2.015000e+03  0.000000e+00    2.100480e+05\n",
      "50%    3.007320e+05  2.019000e+03  1.000000e+00    3.100520e+05\n",
      "75%    6.008710e+05  2.021000e+03  1.000000e+00    5.160030e+05\n",
      "max    9.208190e+05  2.023000e+03  3.000000e+00    8.603000e+05\n",
      "\n",
      "====================================================================================================\n",
      "Missing Values Statistics:\n",
      "====================================================================================================\n",
      "                Missing Count  Missing Ratio(%)\n",
      "patentname                  4              0.00\n",
      "sameno                2507551             79.18\n",
      "agent                  268873              8.49\n",
      "agency                 268872              8.49\n",
      "apppubdate            2507551             79.18\n",
      "explanation             37338              1.18\n",
      "applicantemail           6418              0.20\n",
      "\n",
      "====================================================================================================\n",
      "Starting column filtering...\n",
      "====================================================================================================\n",
      "\n",
      "Filtered data shape: 3166975 rows × 4 columns\n",
      "\n",
      "First 10 rows of filtered data:\n",
      "   stkcd  accper          name         patentname\n",
      "0      1    2019    平安银行股份有限公司  手机的业绩数据分析显示图形用户界面\n",
      "1      1    2020    平安银行股份有限公司             一种录音胸卡\n",
      "2      1    2010  深圳发展银行股份有限公司            信用卡(爽卡)\n",
      "3      1    2013    平安银行股份有限公司           一种安全认证方法\n",
      "4      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面\n",
      "5      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面\n",
      "6      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面\n",
      "7      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面\n",
      "8      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面\n",
      "9      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面\n",
      "\n",
      "Filtered data info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3166975 entries, 0 to 3166974\n",
      "Data columns (total 4 columns):\n",
      " #   Column      Dtype \n",
      "---  ------      ----- \n",
      " 0   stkcd       int64 \n",
      " 1   accper      int64 \n",
      " 2   name        object\n",
      " 3   patentname  object\n",
      "dtypes: int64(2), object(2)\n",
      "memory usage: 96.6+ MB\n",
      "\n",
      "Missing values in filtered data:\n",
      "            Missing Count  Missing Ratio(%)\n",
      "stkcd                   0               0.0\n",
      "accper                  0               0.0\n",
      "name                    0               0.0\n",
      "patentname              4               0.0\n",
      "\n",
      "====================================================================================================\n",
      "Data successfully saved to: /Users/xiaoquanliu/Desktop/工作论文——绿色专利/上市公司与子公司授权专利明细情况表/CSP_PatDetInfo_filtered.csv\n",
      "====================================================================================================\n",
      "Saved data contains 3166975 rows, 4 columns\n",
      "Columns: ['stkcd', 'accper', 'name', 'patentname']\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "file_path = '/Users/xiaoquanliu/Desktop/工作论文——绿色专利/上市公司与子公司授权专利明细情况表/CSP_PatDetInfo_merged_full.csv'\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"First 10 rows:\")\n",
    "print(\"=\" * 100)\n",
    "print(df.head(10))\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Basic Data Information:\")\n",
    "print(\"=\" * 100)\n",
    "print(f\"Data shape: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "print(f\"\\nColumn list:\")\n",
    "for i, col in enumerate(df.columns, 1):\n",
    "    print(f\"{i}. {col}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Detailed Data Structure:\")\n",
    "print(\"=\" * 100)\n",
    "df.info()\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Descriptive Statistics for Numerical Variables:\")\n",
    "print(\"=\" * 100)\n",
    "print(df.describe())\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Missing Values Statistics:\")\n",
    "print(\"=\" * 100)\n",
    "missing_stats = pd.DataFrame({\n",
    "    'Missing Count': df.isnull().sum(),\n",
    "    'Missing Ratio(%)': (df.isnull().sum() / len(df) * 100).round(2)\n",
    "})\n",
    "print(missing_stats[missing_stats['Missing Count'] > 0])\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"Starting column filtering...\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "columns_to_keep = ['stkcd', 'accper', 'name', 'patentname']\n",
    "\n",
    "missing_columns = [col for col in columns_to_keep if col not in df.columns]\n",
    "if missing_columns:\n",
    "    print(f\"Warning: The following columns are missing: {missing_columns}\")\n",
    "    print(f\"Available columns: {list(df.columns)}\")\n",
    "else:\n",
    "    df_filtered = df[columns_to_keep].copy()\n",
    "    \n",
    "    print(f\"\\nFiltered data shape: {df_filtered.shape[0]} rows × {df_filtered.shape[1]} columns\")\n",
    "    print(\"\\nFirst 10 rows of filtered data:\")\n",
    "    print(df_filtered.head(10))\n",
    "    \n",
    "    print(\"\\nFiltered data info:\")\n",
    "    df_filtered.info()\n",
    "    \n",
    "    print(\"\\nMissing values in filtered data:\")\n",
    "    missing_filtered = pd.DataFrame({\n",
    "        'Missing Count': df_filtered.isnull().sum(),\n",
    "        'Missing Ratio(%)': (df_filtered.isnull().sum() / len(df_filtered) * 100).round(2)\n",
    "    })\n",
    "    print(missing_filtered)\n",
    "    \n",
    "    output_path = '/Users/xiaoquanliu/Desktop/工作论文——绿色专利/上市公司与子公司授权专利明细情况表/CSP_PatDetInfo_filtered.csv'\n",
    "    df_filtered.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(f\"Data successfully saved to: {output_path}\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Saved data contains {len(df_filtered)} rows, {len(df_filtered.columns)} columns\")\n",
    "    print(f\"Columns: {list(df_filtered.columns)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "421972ae-9e4a-499a-aa27-aa0e0b144353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading file: /Users/xiaoquanliu/Desktop/工作论文——绿色专利/上市公司与子公司授权专利明细情况表/CSP_PatDetInfo_merged_full.csv\n",
      "\n",
      "====================================================================================================\n",
      "First 10 rows preview:\n",
      "====================================================================================================\n",
      "   stkcd  accper          name  relid       grantno      patentee  \\\n",
      "0      1    2019    平安银行股份有限公司      0  CN305956746S    平安银行股份有限公司   \n",
      "1      1    2020    平安银行股份有限公司      0  CN212516570U    平安银行股份有限公司   \n",
      "2      1    2010  深圳发展银行股份有限公司      0  CN301426805S  深圳发展银行股份有限公司   \n",
      "3      1    2013    平安银行股份有限公司      0  CN103139210B    平安银行股份有限公司   \n",
      "4      1    2016    平安银行股份有限公司      0  CN304061944S    平安银行股份有限公司   \n",
      "5      1    2016    平安银行股份有限公司      0  CN304061945S    平安银行股份有限公司   \n",
      "6      1    2016    平安银行股份有限公司      0  CN304061946S    平安银行股份有限公司   \n",
      "7      1    2016    平安银行股份有限公司      0  CN304065945S    平安银行股份有限公司   \n",
      "8      1    2016    平安银行股份有限公司      0  CN304065946S    平安银行股份有限公司   \n",
      "9      1    2016    平安银行股份有限公司      0  CN304065947S    平安银行股份有限公司   \n",
      "\n",
      "         applino         patentname  \\\n",
      "0  2019305565562  手机的业绩数据分析显示图形用户界面   \n",
      "1  2020215432865             一种录音胸卡   \n",
      "2  2010301942648            信用卡(爽卡)   \n",
      "3  2013100478413           一种安全认证方法   \n",
      "4  2016303943680      用于智能终端的图形用户界面   \n",
      "5  2016303943727      用于智能终端的图形用户界面   \n",
      "6  2016303946636      用于智能终端的图形用户界面   \n",
      "7  2016303943731      用于智能终端的图形用户界面   \n",
      "8  2016303946621      用于智能终端的图形用户界面   \n",
      "9  2016303946674      用于智能终端的图形用户界面   \n",
      "\n",
      "                                             classno     appdate  \\\n",
      "0                                14-03(12);14-04(12)  2019-10-12   \n",
      "1                                G11C7/16(2006.01)I;  2020-07-29   \n",
      "2                                              19-08  2010-06-02   \n",
      "3  H04L29/06(2006.01)I;H04L9/32(2006.01)I;G06Q40/...  2013-02-06   \n",
      "4                                14-03(10);14-04(10)  2016-08-16   \n",
      "5                                14-03(10);14-04(10)  2016-08-16   \n",
      "6                                14-03(10);14-04(10)  2016-08-16   \n",
      "7                                14-03(10);14-04(10)  2016-08-16   \n",
      "8                                14-03(10);14-04(10)  2016-08-16   \n",
      "9                                14-03(10);14-04(10)  2016-08-16   \n",
      "\n",
      "         sameno  agent               agency  apppubdate grantpubdate  \\\n",
      "0           NaN     刘欣     广州华进联合专利商标代理有限公司         NaN   2020-07-31   \n",
      "1           NaN    谭果林  深圳众鼎专利商标代理事务所(普通合伙)         NaN   2021-02-09   \n",
      "2           NaN    李新林           深圳市精英专利事务所         NaN   2010-12-29   \n",
      "3  CN103139210A    李新林           深圳市精英专利事务所  2013-06-05   2016-09-14   \n",
      "4           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-01   \n",
      "5           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-01   \n",
      "6           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-01   \n",
      "7           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-08   \n",
      "8           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-08   \n",
      "9           NaN  张洋;黄健     北京同立钧成知识产权代理有限公司         NaN   2017-03-08   \n",
      "\n",
      "                  inventor type  \\\n",
      "0                      徐继腾    D   \n",
      "1  王晟宇;张舒婷;赖众程;何利斌;杨念慈;高洪喜    U   \n",
      "2                  徐义龙;彭小军    D   \n",
      "3       张元良;李耀星;李恒;廖小荣;黄劲宾    I   \n",
      "4  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "5  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "6  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "7  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "8  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "9  姚贵平;郭蕴川;陈洁茹;陈爱红;杜晓敏;管仕仲    D   \n",
      "\n",
      "                                         explanation  \\\n",
      "0  1.本外观设计产品的名称：手机的业绩数据分析显示图形用户界面。2.本外观设计产品的用途：本外...   \n",
      "1  本实用新型公开了一种录音胸卡，应用于录音技术领域，用于解决现有的录音设备录音效果受外界噪音影...   \n",
      "2  1.本设计产品名称为“信用卡(爽卡)”；2.本产品是一种银行储蓄卡；3.设计要点在于本产品的...   \n",
      "3  本发明公开一种安全认证方法，其包括以下步骤：S10，申请移动安全认证；S20，将移动通讯设备...   \n",
      "4  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "5  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "6  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "7  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "8  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "9  1．本外观设计产品的名称：用于智能终端的图形用户界面。2．本外观设计产品的用途：本外观设计产...   \n",
      "\n",
      "           applicantaddress  applicantemail  \n",
      "0        广东省深圳市罗湖区深南东路5047号        518021.0  \n",
      "1        广东省深圳市罗湖区深南东路5047号        518000.0  \n",
      "2        广东省深圳市罗湖区深南东路5047号        518000.0  \n",
      "3        广东省深圳市罗湖区深南东路5047号        518000.0  \n",
      "4  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "5  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "6  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "7  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "8  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "9  广东省深圳市罗湖区深圳东路5047号平安银行大厦        518000.0  \n",
      "\n",
      "====================================================================================================\n",
      "Data Structure Description:\n",
      "====================================================================================================\n",
      "Dimensions: 3166975 rows × 20 columns\n",
      "\n",
      "Data Info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3166975 entries, 0 to 3166974\n",
      "Data columns (total 20 columns):\n",
      " #   Column            Dtype  \n",
      "---  ------            -----  \n",
      " 0   stkcd             int64  \n",
      " 1   accper            int64  \n",
      " 2   name              object \n",
      " 3   relid             int64  \n",
      " 4   grantno           object \n",
      " 5   patentee          object \n",
      " 6   applino           object \n",
      " 7   patentname        object \n",
      " 8   classno           object \n",
      " 9   appdate           object \n",
      " 10  sameno            object \n",
      " 11  agent             object \n",
      " 12  agency            object \n",
      " 13  apppubdate        object \n",
      " 14  grantpubdate      object \n",
      " 15  inventor          object \n",
      " 16  type              object \n",
      " 17  explanation       object \n",
      " 18  applicantaddress  object \n",
      " 19  applicantemail    float64\n",
      "dtypes: float64(1), int64(3), object(16)\n",
      "memory usage: 483.2+ MB\n",
      "\n",
      "====================================================================================================\n",
      "Filtering variables...\n",
      "====================================================================================================\n",
      "Filtering successful!\n",
      "Filtered dimensions: 3166975 rows × 6 columns\n",
      "\n",
      "Filtered data preview:\n",
      "   stkcd  accper          name         patentname     appdate        applino\n",
      "0      1    2019    平安银行股份有限公司  手机的业绩数据分析显示图形用户界面  2019-10-12  2019305565562\n",
      "1      1    2020    平安银行股份有限公司             一种录音胸卡  2020-07-29  2020215432865\n",
      "2      1    2010  深圳发展银行股份有限公司            信用卡(爽卡)  2010-06-02  2010301942648\n",
      "3      1    2013    平安银行股份有限公司           一种安全认证方法  2013-02-06  2013100478413\n",
      "4      1    2016    平安银行股份有限公司      用于智能终端的图形用户界面  2016-08-16  2016303943680\n",
      "\n",
      "====================================================================================================\n",
      "Processing complete!\n",
      "====================================================================================================\n",
      "File saved to: /Users/xiaoquanliu/Desktop/工作论文——绿色专利/上市公司与子公司授权专利明细情况表/CSP_PatDetInfo_filtered_6cols.csv\n",
      "Included variables: stkcd, accper, name, patentname, appdate, applino\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_dir = '/Users/xiaoquanliu/Desktop/工作论文——绿色专利/上市公司与子公司授权专利明细情况表/'\n",
    "file_name = 'CSP_PatDetInfo_merged_full.csv'\n",
    "file_path = os.path.join(input_dir, file_name)\n",
    "\n",
    "print(f\"Reading file: {file_path}\")\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "    \n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"First 10 rows preview:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(df.head(10))\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"Data Structure Description:\")\n",
    "    print(\"=\" * 100)\n",
    "    print(f\"Dimensions: {df.shape[0]} rows × {df.shape[1]} columns\")\n",
    "    print(\"\\nData Info:\")\n",
    "    df.info()\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 100)\n",
    "    print(\"Filtering variables...\")\n",
    "    print(\"=\" * 100)\n",
    "\n",
    "    columns_to_keep = ['stkcd', 'accper', 'name', 'patentname', 'appdate', 'applino']\n",
    "\n",
    "    missing_cols = [col for col in columns_to_keep if col not in df.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Error: The following columns were not found: {missing_cols}\")\n",
    "        print(\"Please check column names in the original data.\")\n",
    "        print(f\"Original columns: {list(df.columns)}\")\n",
    "    else:\n",
    "        df_filtered = df[columns_to_keep].copy()\n",
    "        \n",
    "        print(\"Filtering successful!\")\n",
    "        print(f\"Filtered dimensions: {df_filtered.shape[0]} rows × {df_filtered.shape[1]} columns\")\n",
    "        print(\"\\nFiltered data preview:\")\n",
    "        print(df_filtered.head())\n",
    "\n",
    "        output_file_name = 'CSP_PatDetInfo_filtered_6cols.csv'\n",
    "        output_path = os.path.join(input_dir, output_file_name)\n",
    "        \n",
    "        df_filtered.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"\\n\" + \"=\" * 100)\n",
    "        print(\"Processing complete!\")\n",
    "        print(\"=\" * 100)\n",
    "        print(f\"File saved to: {output_path}\")\n",
    "        print(f\"Included variables: {', '.join(columns_to_keep)}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Error: File not found, please check the path: {file_path}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unknown error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f0f8bd4d-769a-4a88-bf5a-15f818ec5c36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "Step 1: Importing data...\n",
      "================================================================================\n",
      "CSP_Pat (General Patents) original rows: 1,048,575\n",
      "GP_Pat  (Green Patents) original rows: 348,986\n",
      "\n",
      "================================================================================\n",
      "Step 2: Comparing applino (Application Number)...\n",
      "================================================================================\n",
      "Comparison complete.\n",
      "Overlapping application numbers found in CSP_Pat: 7,642\n",
      "Overlap ratio: 0.73%\n",
      "\n",
      "Overlap examples (First 5):\n",
      "['200520054388X' '21037345' '22053131' '200420102842X' '201010191606X']\n",
      "\n",
      "================================================================================\n",
      "Step 3: Removing overlapping rows and saving...\n",
      "================================================================================\n",
      "Processing Summary:\n",
      "1. Original data count:    1,048,575\n",
      "2. Removed overlaps:    -      7,642\n",
      "3. Remaining data count: =  1,040,933\n",
      "----------------------------------------\n",
      "New file saved to: /Users/xiaoquanliu/Desktop/CSP_Pat_NonGreen.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = '/Users/xiaoquanliu/Desktop/'\n",
    "csp_file = os.path.join(base_path, 'CSP_Pat.csv')\n",
    "gp_file = os.path.join(base_path, 'GP_Pat.csv')\n",
    "output_file = os.path.join(base_path, 'CSP_Pat_NonGreen.csv')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"Step 1: Importing data...\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "try:\n",
    "    df_csp = pd.read_csv(csp_file, low_memory=False)\n",
    "    df_gp = pd.read_csv(gp_file, low_memory=False)\n",
    "\n",
    "    print(f\"CSP_Pat (General Patents) original rows: {len(df_csp):,}\")\n",
    "    print(f\"GP_Pat  (Green Patents) original rows: {len(df_gp):,}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 2: Comparing applino (Application Number)...\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    if 'applino' not in df_csp.columns or 'applino' not in df_gp.columns:\n",
    "        raise ValueError(\"Error: 'applino' column missing in input files.\")\n",
    "\n",
    "    df_csp['applino_clean'] = df_csp['applino'].astype(str).str.strip()\n",
    "    gp_applinos = set(df_gp['applino'].astype(str).str.strip())\n",
    "\n",
    "    overlap_mask = df_csp['applino_clean'].isin(gp_applinos)\n",
    "    \n",
    "    overlap_rows = df_csp[overlap_mask]\n",
    "    \n",
    "    print(f\"Comparison complete.\")\n",
    "    print(f\"Overlapping application numbers found in CSP_Pat: {len(overlap_rows):,}\")\n",
    "    print(f\"Overlap ratio: {len(overlap_rows) / len(df_csp) * 100:.2f}%\")\n",
    "\n",
    "    if len(overlap_rows) > 0:\n",
    "        print(\"\\nOverlap examples (First 5):\")\n",
    "        print(overlap_rows['applino'].head(5).values)\n",
    "\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(\"Step 3: Removing overlapping rows and saving...\")\n",
    "    print(\"=\" * 80)\n",
    "\n",
    "    df_clean = df_csp[~overlap_mask].copy()\n",
    "\n",
    "    df_clean.drop(columns=['applino_clean'], inplace=True)\n",
    "\n",
    "    df_clean.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "\n",
    "    print(f\"Processing Summary:\")\n",
    "    print(f\"1. Original data count:   {len(df_csp):>10,}\")\n",
    "    print(f\"2. Removed overlaps:    - {len(overlap_rows):>10,}\")\n",
    "    print(f\"3. Remaining data count: = {len(df_clean):>10,}\")\n",
    "    print(\"-\" * 40)\n",
    "    print(f\"New file saved to: {output_file}\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Please check the path.\\nDetails: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Unknown error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2dd1bd6-d7c0-4430-b523-be2b846afa5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Non-Green Patents (NG) rows: 240630\n",
      "Green Patents (GP) rows: 348986\n",
      "\n",
      "Processing date formats...\n",
      "\n",
      "Aggregating non-green patent texts (by date)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/3891007937.py:18: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_ng['appdate'] = pd.to_datetime(df_ng['appdate'])\n",
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/3891007937.py:19: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_gp['appdate'] = pd.to_datetime(df_gp['appdate'])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calculating rolling text window for past 10 days [t-10, t-1]...\n",
      "\n",
      "Matching rolling window data to green patent data...\n",
      "\n",
      "Preview of first 5 rows:\n",
      "     appdate                  patentname context_preview\n",
      "0 2022-08-30          一种银联收单争议案件的建案方法及装置             ...\n",
      "1 2022-09-07              基于云端的远程控制方法及装置             ...\n",
      "2 2022-09-16   基于实时录制的生产流量重跑风险程序的回放方法及系统             ...\n",
      "3 2022-06-15   电梯消毒方法、装置、计算机设备及计算机可读存储介质             ...\n",
      "4 2022-09-29     房屋的定位方法、装置、计算机设备及可读存储介质             ...\n",
      "\n",
      "Saving data to: /Users/xiaoquanliu/Desktop/GP_Pat_Rolling_10Days.csv\n",
      "Processing complete! File size approx: 4243.82 MB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "base_path = '/Users/xiaoquanliu/Desktop/'\n",
    "file_ng = os.path.join(base_path, 'CSP_Pat_Ng.csv')\n",
    "file_gp = os.path.join(base_path, 'GP_Pat.csv')\n",
    "output_path = os.path.join(base_path, 'GP_Pat_Rolling_10Days.csv')\n",
    "\n",
    "print(\"Reading data...\")\n",
    "try:\n",
    "    df_ng = pd.read_csv(file_ng)\n",
    "    df_gp = pd.read_csv(file_gp)\n",
    "    \n",
    "    print(f\"Non-Green Patents (NG) rows: {len(df_ng)}\")\n",
    "    print(f\"Green Patents (GP) rows: {len(df_gp)}\")\n",
    "\n",
    "    print(\"\\nProcessing date formats...\")\n",
    "    df_ng['appdate'] = pd.to_datetime(df_ng['appdate'])\n",
    "    df_gp['appdate'] = pd.to_datetime(df_gp['appdate'])\n",
    "\n",
    "    df_ng['patentname_ng'] = df_ng['patentname_ng'].astype(str).fillna('')\n",
    "\n",
    "    print(\"\\nAggregating non-green patent texts (by date)...\")\n",
    "    \n",
    "    df_ng_daily = df_ng.groupby('appdate')['patentname_ng'].apply(lambda x: ' '.join(x)).reset_index()\n",
    "    \n",
    "    df_ng_daily.set_index('appdate', inplace=True)\n",
    "    \n",
    "    full_date_range = pd.date_range(start=df_ng_daily.index.min(), end=df_gp['appdate'].max(), freq='D')\n",
    "    df_ng_daily = df_ng_daily.reindex(full_date_range, fill_value='')\n",
    "    \n",
    "    print(\"Calculating rolling text window for past 10 days [t-10, t-1]...\")\n",
    "    \n",
    "    df_ng_daily['rolling_context'] = ''\n",
    "    \n",
    "    for i in range(1, 11):\n",
    "        shifted_text = df_ng_daily['patentname_ng'].shift(i).fillna('')\n",
    "        df_ng_daily['rolling_context'] = df_ng_daily['rolling_context'] + ' ' + shifted_text\n",
    "\n",
    "    df_ng_daily['rolling_context'] = df_ng_daily['rolling_context'].str.strip()\n",
    "    \n",
    "    df_ng_daily = df_ng_daily.reset_index().rename(columns={'index': 'appdate'})\n",
    "\n",
    "    print(\"\\nMatching rolling window data to green patent data...\")\n",
    "    \n",
    "    df_merged = pd.merge(\n",
    "        df_gp,\n",
    "        df_ng_daily[['appdate', 'rolling_context']],\n",
    "        on='appdate',\n",
    "        how='left'\n",
    "    )\n",
    "\n",
    "    df_merged.rename(columns={'rolling_context': 'ng_patents_last_10days'}, inplace=True)\n",
    "    \n",
    "    df_merged['ng_patents_last_10days'] = df_merged['ng_patents_last_10days'].fillna('')\n",
    "\n",
    "    print(\"\\nPreview of first 5 rows:\")\n",
    "    preview = df_merged[['appdate', 'patentname', 'ng_patents_last_10days']].head()\n",
    "    preview['context_preview'] = preview['ng_patents_last_10days'].str[:50] + \"...\"\n",
    "    print(preview[['appdate', 'patentname', 'context_preview']])\n",
    "\n",
    "    print(f\"\\nSaving data to: {output_path}\")\n",
    "    df_merged.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    file_size_mb = os.path.getsize(output_path) / (1024 * 1024)\n",
    "    print(f\"Processing complete! File size approx: {file_size_mb:.2f} MB\")\n",
    "\n",
    "except FileNotFoundError as e:\n",
    "    print(f\"Error: File not found. Details: {e}\")\n",
    "except Exception as e:\n",
    "    print(f\"Error occurred: {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4036272e-c092-4421-9f7f-b7cf38ec24ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/1252227722.py:21: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_ng['appdate'] = pd.to_datetime(df_ng['appdate'], errors='coerce')\n",
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/1252227722.py:22: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_gp['appdate'] = pd.to_datetime(df_gp['appdate'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded. GP samples: 348986, CSP_Ng samples: 240630\n",
      "Starting time window alignment and text integration (this may take some time)...\n",
      "Processed 348900/348986 samples...\n",
      "Processing complete, saving...\n",
      "File saved to: /Users/xiaoquanliu/Desktop/GP_Pat_CSPLag60D.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "def process_patent_data():\n",
    "    base_path = '/Users/xiaoquanliu/Desktop/'\n",
    "    file_ng = os.path.join(base_path, 'CSP_Pat_Ng.csv')\n",
    "    file_gp = os.path.join(base_path, 'GP_Pat.csv')\n",
    "    output_file = os.path.join(base_path, 'GP_Pat_CSPLag60D.csv')\n",
    "\n",
    "    print(\"Reading data...\")\n",
    "    \n",
    "    try:\n",
    "        df_ng = pd.read_csv(file_ng)\n",
    "        df_gp = pd.read_csv(file_gp)\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"UTF-8 read failed, trying GB18030 encoding...\")\n",
    "        df_ng = pd.read_csv(file_ng, encoding='gb18030')\n",
    "        df_gp = pd.read_csv(file_gp, encoding='gb18030')\n",
    "\n",
    "    df_ng['appdate'] = pd.to_datetime(df_ng['appdate'], errors='coerce')\n",
    "    df_gp['appdate'] = pd.to_datetime(df_gp['appdate'], errors='coerce')\n",
    "\n",
    "    df_ng = df_ng.dropna(subset=['appdate'])\n",
    "    df_gp = df_gp.dropna(subset=['appdate'])\n",
    "\n",
    "    df_ng = df_ng.sort_values('appdate')\n",
    "\n",
    "    print(f\"Data loaded. GP samples: {len(df_gp)}, CSP_Ng samples: {len(df_ng)}\")\n",
    "    print(\"Starting time window alignment and text integration (this may take some time)...\")\n",
    "\n",
    "    aligned_texts = []\n",
    "    \n",
    "    ng_dates = df_ng['appdate'].values\n",
    "    ng_names = df_ng['patentname_ng'].astype(str).values\n",
    "\n",
    "    for idx, row in df_gp.iterrows():\n",
    "        t = row['appdate']\n",
    "        \n",
    "        start_date = t - timedelta(days=60) \n",
    "        end_date = t - timedelta(days=1)\n",
    "        \n",
    "        mask = (df_ng['appdate'] >= start_date) & (df_ng['appdate'] <= end_date)\n",
    "        \n",
    "        matched_names = df_ng.loc[mask, 'patentname_ng']\n",
    "        \n",
    "        valid_names = matched_names.dropna().astype(str).tolist()\n",
    "        \n",
    "        if valid_names:\n",
    "            combined_text = \" \".join(valid_names)\n",
    "        else:\n",
    "            combined_text = \"\"\n",
    "            \n",
    "        aligned_texts.append(combined_text)\n",
    "        \n",
    "        if (idx + 1) % 100 == 0:\n",
    "            print(f\"Processed {idx + 1}/{len(df_gp)} samples...\", end='\\r')\n",
    "\n",
    "    df_gp['context_docs'] = aligned_texts\n",
    "\n",
    "    print(\"\\nProcessing complete, saving...\")\n",
    "    df_gp.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(f\"File saved to: {output_file}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    process_patent_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5e4a53e1-e8db-4c92-8590-8eebfb822477",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Cleaning data and converting time frequency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/3697667354.py:28: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_ng['appdate'] = pd.to_datetime(df_ng['appdate'], errors='coerce')\n",
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/3697667354.py:29: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_gp['appdate'] = pd.to_datetime(df_gp['appdate'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating texts by [Stock Code + Month]...\n",
      "Merging into balanced panel structure...\n",
      "Processing complete, saving to: /Users/xiaoquanliu/Desktop/Panel_Patents_Monthly.csv\n",
      "Task successfully completed!\n",
      "Output data preview:\n",
      "  stkcd month_period                                          gp_text  \\\n",
      "0     1      2010-06                                                    \n",
      "1     1      2013-02                                         一种安全认证方法   \n",
      "2     1      2016-08                                                    \n",
      "3     1      2017-01   业务数据处理的方法及信息交换控制系统  交易入账控制方法及系统  交易处理的方法及交易服务器   \n",
      "4     1      2018-12                           一种高价值客户识别方法、系统、设备及存储介质   \n",
      "\n",
      "                                             ng_text  \n",
      "0                                            信用卡(爽卡)  \n",
      "1                                                     \n",
      "2  用于智能终端的图形用户界面 用于智能终端的图形用户界面 用于智能终端的图形用户界面 用于智能...  \n",
      "3                                                     \n",
      "4                                                     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def build_patent_panel_data():\n",
    "    base_path = '/Users/xiaoquanliu/Desktop/'\n",
    "    file_ng = os.path.join(base_path, 'CSP_Pat_Ng.csv')\n",
    "    file_gp = os.path.join(base_path, 'GP_Pat.csv')\n",
    "    output_file = os.path.join(base_path, 'Panel_Patents_Monthly.csv')\n",
    "\n",
    "    print(\"Reading data...\")\n",
    "\n",
    "    try:\n",
    "        df_ng = pd.read_csv(file_ng)\n",
    "        df_gp = pd.read_csv(file_gp)\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"UTF-8 read failed, trying GB18030 encoding...\")\n",
    "        df_ng = pd.read_csv(file_ng, encoding='gb18030')\n",
    "        df_gp = pd.read_csv(file_gp, encoding='gb18030')\n",
    "\n",
    "    print(\"Cleaning data and converting time frequency...\")\n",
    "\n",
    "    df_ng.columns = [c.lower() for c in df_ng.columns]\n",
    "    df_gp.columns = [c.lower() for c in df_gp.columns]\n",
    "\n",
    "    df_ng['stkcd'] = df_ng['stkcd'].astype(str)\n",
    "    df_gp['stkcd'] = df_gp['stkcd'].astype(str)\n",
    "\n",
    "    df_ng['appdate'] = pd.to_datetime(df_ng['appdate'], errors='coerce')\n",
    "    df_gp['appdate'] = pd.to_datetime(df_gp['appdate'], errors='coerce')\n",
    "\n",
    "    df_ng = df_ng.dropna(subset=['appdate'])\n",
    "    df_gp = df_gp.dropna(subset=['appdate'])\n",
    "\n",
    "    df_ng['month_period'] = df_ng['appdate'].dt.to_period('M')\n",
    "    df_gp['month_period'] = df_gp['appdate'].dt.to_period('M')\n",
    "\n",
    "    print(\"Aggregating texts by [Stock Code + Month]...\")\n",
    "\n",
    "    def join_text(texts):\n",
    "        return \" \".join(texts.dropna().astype(str).tolist())\n",
    "\n",
    "    gp_panel = df_gp.groupby(['stkcd', 'month_period'])['patentname'].apply(join_text).reset_index()\n",
    "    gp_panel.rename(columns={'patentname': 'gp_text'}, inplace=True)\n",
    "\n",
    "    ng_panel = df_ng.groupby(['stkcd', 'month_period'])['patentname_ng'].apply(join_text).reset_index()\n",
    "    ng_panel.rename(columns={'patentname_ng': 'ng_text'}, inplace=True)\n",
    "\n",
    "    print(\"Merging into balanced panel structure...\")\n",
    "\n",
    "    df_merged = pd.merge(gp_panel, ng_panel, on=['stkcd', 'month_period'], how='outer')\n",
    "\n",
    "    df_merged['gp_text'] = df_merged['gp_text'].fillna('')\n",
    "    df_merged['ng_text'] = df_merged['ng_text'].fillna('')\n",
    "\n",
    "    df_merged = df_merged.sort_values(['stkcd', 'month_period'])\n",
    "\n",
    "    print(f\"Processing complete, saving to: {output_file}\")\n",
    "    \n",
    "    df_merged['month_period'] = df_merged['month_period'].astype(str)\n",
    "    \n",
    "    df_merged.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"Task successfully completed!\")\n",
    "    print(f\"Output data preview:\\n{df_merged.head()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_patent_panel_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "190270fc-12b7-45ae-918d-65d7537ef68d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Cleaning data and converting time frequency...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/3774039834.py:31: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_ng['appdate'] = pd.to_datetime(df_ng['appdate'], errors='coerce')\n",
      "/var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/ipykernel_14466/3774039834.py:32: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df_gp['appdate'] = pd.to_datetime(df_gp['appdate'], errors='coerce')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aggregating texts by [Stock Code + Month]...\n",
      "Merging into balanced panel structure...\n",
      "Processing complete, saving to: /Users/xiaoquanliu/Desktop/Panel_Patents_Monthly.csv\n",
      "Task successfully completed!\n",
      "Output data preview:\n",
      "  stkcd     date                                           gp_pat  \\\n",
      "0     1  2010-06                                                    \n",
      "1     1  2013-02                                         一种安全认证方法   \n",
      "2     1  2016-08                                                    \n",
      "3     1  2017-01   业务数据处理的方法及信息交换控制系统  交易入账控制方法及系统  交易处理的方法及交易服务器   \n",
      "4     1  2018-12                           一种高价值客户识别方法、系统、设备及存储介质   \n",
      "\n",
      "                                              ng_pat  \n",
      "0                                            信用卡(爽卡)  \n",
      "1                                                     \n",
      "2  用于智能终端的图形用户界面 用于智能终端的图形用户界面 用于智能终端的图形用户界面 用于智能...  \n",
      "3                                                     \n",
      "4                                                     \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def build_patent_panel_data():\n",
    "    base_path = '/Users/xiaoquanliu/Desktop/'\n",
    "    file_ng = os.path.join(base_path, 'CSP_Pat_Ng.csv')\n",
    "    file_gp = os.path.join(base_path, 'GP_Pat.csv')\n",
    "    output_file = os.path.join(base_path, 'Panel_Patents_Monthly.csv')\n",
    "\n",
    "    print(\"Reading data...\")\n",
    "\n",
    "    try:\n",
    "        df_ng = pd.read_csv(file_ng)\n",
    "        df_gp = pd.read_csv(file_gp)\n",
    "    except UnicodeDecodeError:\n",
    "        print(\"UTF-8 read failed, trying GB18030 encoding...\")\n",
    "        df_ng = pd.read_csv(file_ng, encoding='gb18030')\n",
    "        df_gp = pd.read_csv(file_gp, encoding='gb18030')\n",
    "\n",
    "    print(\"Cleaning data and converting time frequency...\")\n",
    "\n",
    "    # Standardize column names\n",
    "    df_ng.columns = [c.lower() for c in df_ng.columns]\n",
    "    df_gp.columns = [c.lower() for c in df_gp.columns]\n",
    "\n",
    "    # Ensure stock codes are strings\n",
    "    df_ng['stkcd'] = df_ng['stkcd'].astype(str)\n",
    "    df_gp['stkcd'] = df_gp['stkcd'].astype(str)\n",
    "\n",
    "    # Convert dates\n",
    "    df_ng['appdate'] = pd.to_datetime(df_ng['appdate'], errors='coerce')\n",
    "    df_gp['appdate'] = pd.to_datetime(df_gp['appdate'], errors='coerce')\n",
    "\n",
    "    # Drop rows with missing dates\n",
    "    df_ng = df_ng.dropna(subset=['appdate'])\n",
    "    df_gp = df_gp.dropna(subset=['appdate'])\n",
    "\n",
    "    # Create month period column\n",
    "    df_ng['month_period'] = df_ng['appdate'].dt.to_period('M')\n",
    "    df_gp['month_period'] = df_gp['appdate'].dt.to_period('M')\n",
    "\n",
    "    print(\"Aggregating texts by [Stock Code + Month]...\")\n",
    "\n",
    "    def join_text(texts):\n",
    "        return \" \".join(texts.dropna().astype(str).tolist())\n",
    "\n",
    "    # Group Green Patents\n",
    "    gp_panel = df_gp.groupby(['stkcd', 'month_period'])['patentname'].apply(join_text).reset_index()\n",
    "    # Rename to 'gp_pat' for consistency with Part 7\n",
    "    gp_panel.rename(columns={'patentname': 'gp_pat'}, inplace=True)\n",
    "\n",
    "    # Group Non-Green Patents\n",
    "    ng_panel = df_ng.groupby(['stkcd', 'month_period'])['patentname_ng'].apply(join_text).reset_index()\n",
    "    # Rename to 'ng_pat' for consistency with Part 7\n",
    "    ng_panel.rename(columns={'patentname_ng': 'ng_pat'}, inplace=True)\n",
    "\n",
    "    print(\"Merging into balanced panel structure...\")\n",
    "\n",
    "    # Outer join to keep all records\n",
    "    df_merged = pd.merge(gp_panel, ng_panel, on=['stkcd', 'month_period'], how='outer')\n",
    "\n",
    "    # Fill NaN with empty strings\n",
    "    df_merged['gp_pat'] = df_merged['gp_pat'].fillna('')\n",
    "    df_merged['ng_pat'] = df_merged['ng_pat'].fillna('')\n",
    "\n",
    "    # Rename 'month_period' to 'date' for Part 7 compatibility\n",
    "    df_merged.rename(columns={'month_period': 'date'}, inplace=True)\n",
    "\n",
    "    # Sort\n",
    "    df_merged = df_merged.sort_values(['stkcd', 'date'])\n",
    "\n",
    "    print(f\"Processing complete, saving to: {output_file}\")\n",
    "    \n",
    "    # Convert period to string for CSV saving (e.g., '2023-01')\n",
    "    df_merged['date'] = df_merged['date'].astype(str)\n",
    "    \n",
    "    df_merged.to_csv(output_file, index=False, encoding='utf-8-sig')\n",
    "    \n",
    "    print(\"Task successfully completed!\")\n",
    "    print(f\"Output data preview:\\n{df_merged.head()}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    build_patent_panel_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b5a7f2ac-280a-415d-8663-2d222cfbcd79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading data...\n",
      "Data read successfully, total 111036 rows.\n",
      "Processing data...\n",
      "Building historical text accumulation (this may take some time)...\n",
      "Saving data to: /Users/xiaoquanliu/Desktop/Panel_Patents_Aligned_Processed.csv\n",
      "\n",
      "Task complete!\n",
      "Data preview (First 5 rows):\n",
      "   stkcd       date                                           gp_pat  \\\n",
      "0      1 2010-06-01                                              NaN   \n",
      "1      1 2013-02-01                                         一种安全认证方法   \n",
      "2      1 2016-08-01                                              NaN   \n",
      "3      1 2017-01-01   业务数据处理的方法及信息交换控制系统  交易入账控制方法及系统  交易处理的方法及交易服务器   \n",
      "4      1 2018-12-01                           一种高价值客户识别方法、系统、设备及存储介质   \n",
      "\n",
      "                                      ng_pat_history  \n",
      "0                                                     \n",
      "1                                            信用卡(爽卡)  \n",
      "2                                            信用卡(爽卡)  \n",
      "3  信用卡(爽卡) 用于智能终端的图形用户界面 用于智能终端的图形用户界面 用于智能终端的图形用...  \n",
      "4  信用卡(爽卡) 用于智能终端的图形用户界面 用于智能终端的图形用户界面 用于智能终端的图形用...  \n",
      "\n",
      "Verifying concatenation logic for stock 1:\n",
      "   stkcd       date     gp_pat ng_pat_history\n",
      "0      1 2010-06-01        NaN               \n",
      "1      1 2013-02-01   一种安全认证方法        信用卡(爽卡)\n",
      "2      1 2016-08-01        NaN        信用卡(爽卡)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "input_path = '/Users/xiaoquanliu/Desktop/Panel_Patents_Monthly.csv'\n",
    "output_path = '/Users/xiaoquanliu/Desktop/Panel_Patents_Aligned_Processed.csv'\n",
    "\n",
    "if os.path.exists(input_path):\n",
    "    try:\n",
    "        print(\"Reading data...\")\n",
    "        # Now 'date' column exists, so parse_dates will work\n",
    "        df = pd.read_csv(input_path, parse_dates=['date'])\n",
    "        print(f\"Data read successfully, total {len(df)} rows.\")\n",
    "\n",
    "        print(\"Processing data...\")\n",
    "\n",
    "        # Sort by stock and date to ensure correct shifting\n",
    "        df = df.sort_values(by=['stkcd', 'date']).reset_index(drop=True)\n",
    "\n",
    "        # Ensure text columns are strings\n",
    "        df['ng_pat'] = df['ng_pat'].fillna('').astype(str)\n",
    "        \n",
    "        # Add a space after each text to prevent words sticking together during concatenation\n",
    "        df['ng_pat_padded'] = df['ng_pat'].apply(lambda x: x + ' ' if len(x) > 0 else '')\n",
    "\n",
    "        print(\"Building historical text accumulation (this may take some time)...\")\n",
    "\n",
    "        # Shift to get previous period's text (t-1)\n",
    "        df['prev_ng_pat'] = df.groupby('stkcd')['ng_pat_padded'].shift(1).fillna('')\n",
    "\n",
    "        # Cumulative sum of previous texts (from t=1 to t-1)\n",
    "        df['ng_pat_history'] = df.groupby('stkcd')['prev_ng_pat'].transform(lambda x: x.cumsum())\n",
    "\n",
    "        # Clean up whitespace\n",
    "        df['ng_pat_history'] = df['ng_pat_history'].str.strip()\n",
    "\n",
    "        # Select final columns\n",
    "        final_df = df[['stkcd', 'date', 'gp_pat', 'ng_pat_history']]\n",
    "\n",
    "        print(f\"Saving data to: {output_path}\")\n",
    "        final_df.to_csv(output_path, index=False, encoding='utf-8-sig')\n",
    "        \n",
    "        print(\"\\nTask complete!\")\n",
    "        print(\"Data preview (First 5 rows):\")\n",
    "        print(final_df.head())\n",
    "\n",
    "        sample_stk = final_df['stkcd'].iloc[0]\n",
    "        print(f\"\\nVerifying concatenation logic for stock {sample_stk}:\")\n",
    "        print(final_df[final_df['stkcd'] == sample_stk].head(3))\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()\n",
    "else:\n",
    "    print(f\"Error: File {input_path} does not exist.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d586818f-0756-4432-988e-eed81acc4ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.13/site-packages/jieba/_compat.py:18: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Reading data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Loading model from cache /var/folders/cl/wbfw5l6x06qggs_8v4x0__th0000gn/T/jieba.cache\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded, total 111036 rows.\n",
      "2. Performing Chinese tokenization...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading model cost 0.289 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3. Building corpus...\n",
      "   Corpus size after cleaning: 134712\n",
      "4. Initializing model (CBOW mode)...\n",
      "   Building vocabulary...\n",
      "   Starting training (5 epochs)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: 'gensim.models.word2vec_inner.our_dot_float'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model training complete.\n",
      "5. Calculating technological distance...\n",
      "\n",
      "Saving full version to: /Users/xiaoquanliu/Desktop/Panel_Patents_Distance_Full_5vars.csv\n",
      "Saving clean version to: /Users/xiaoquanliu/Desktop/Panel_Patents_Distance_Final_3vars.csv\n",
      "\n",
      "All success!\n",
      "count    33275.000000\n",
      "mean         0.430955\n",
      "std          0.215555\n",
      "min          0.001413\n",
      "25%          0.267343\n",
      "50%          0.397343\n",
      "75%          0.568110\n",
      "max          1.255930\n",
      "Name: tech_distance, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Force single threading to avoid numpy/gensim conflicts\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"OPENBLAS_NUM_THREADS\"] = \"1\"\n",
    "os.environ[\"MKL_NUM_THREADS\"] = \"1\"\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jieba\n",
    "from gensim.models import Word2Vec\n",
    "from scipy.spatial.distance import cosine\n",
    "\n",
    "input_path = '/Users/xiaoquanliu/Desktop/Panel_Patents_Aligned_Processed.csv'\n",
    "output_path_full = '/Users/xiaoquanliu/Desktop/Panel_Patents_Distance_Full_5vars.csv'\n",
    "output_path_clean = '/Users/xiaoquanliu/Desktop/Panel_Patents_Distance_Final_3vars.csv'\n",
    "\n",
    "stopwords_path = None \n",
    "\n",
    "# Word2Vec Parameters\n",
    "VECTOR_SIZE = 200    \n",
    "WINDOW = 4           \n",
    "MIN_COUNT = 1        \n",
    "WORKERS = 1          \n",
    "SG = 0               # CBOW mode\n",
    "EPOCHS = 5           \n",
    "\n",
    "def load_stopwords(path):\n",
    "    stopwords = set()\n",
    "    if path and os.path.exists(path):\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                stopwords.add(line.strip())\n",
    "    else:\n",
    "        # Default basic Chinese stopwords\n",
    "        stopwords = {'的', '了', '和', '是', '在', '与', '对于', '及', '等', '本', '一种', '基于'}\n",
    "    return stopwords\n",
    "\n",
    "def clean_and_tokenize(text, stopwords):\n",
    "    text = str(text)\n",
    "    if len(text.strip()) == 0 or text.lower() == 'nan':\n",
    "        return []\n",
    "    words = jieba.cut(text)\n",
    "    return [str(w).strip() for w in words if w not in stopwords and len(str(w).strip()) > 1]\n",
    "\n",
    "def get_document_vector(words, model):\n",
    "    valid_words = [w for w in words if w in model.wv]\n",
    "    if not valid_words:\n",
    "        return np.zeros(model.vector_size)\n",
    "    vectors = model.wv[valid_words]\n",
    "    return np.mean(vectors, axis=0)\n",
    "\n",
    "def calculate_distance_optimized(vec1, vec2):\n",
    "    if np.all(vec1 == 0) or np.all(vec2 == 0):\n",
    "        return np.nan\n",
    "    raw_distance = cosine(vec1, vec2)\n",
    "    # Cosine distance is 1 - similarity. \n",
    "    # If vectors are identical, distance is 0. If opposite, distance is 2.\n",
    "    final_distance = max(0.0, raw_distance)\n",
    "    return final_distance\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    if os.path.exists(input_path):\n",
    "        print(\"1. Reading data...\")\n",
    "        df = pd.read_csv(input_path)\n",
    "        \n",
    "        # Handle NaN values\n",
    "        df['gp_pat'] = df['gp_pat'].fillna('')\n",
    "        df['ng_pat_history'] = df['ng_pat_history'].fillna('')\n",
    "        \n",
    "        print(f\"Data loaded, total {len(df)} rows.\")\n",
    "\n",
    "        print(\"2. Performing Chinese tokenization...\")\n",
    "        stopwords = load_stopwords(stopwords_path)\n",
    "        df['gp_tokens'] = df['gp_pat'].apply(lambda x: clean_and_tokenize(x, stopwords))\n",
    "        df['history_tokens'] = df['ng_pat_history'].apply(lambda x: clean_and_tokenize(x, stopwords))\n",
    "\n",
    "        print(\"3. Building corpus...\")\n",
    "        # Combine both columns to build a complete vocabulary\n",
    "        raw_corpus = df['gp_tokens'].tolist() + df['history_tokens'].tolist()\n",
    "        \n",
    "        # Filter out short documents\n",
    "        corpus = [doc for doc in raw_corpus if doc and len(doc) >= WINDOW]\n",
    "        \n",
    "        print(f\"   Corpus size after cleaning: {len(corpus)}\")\n",
    "        \n",
    "        if not corpus:\n",
    "            print(\"Error: Cleaned corpus is empty.\")\n",
    "        else:\n",
    "            print(\"4. Initializing model (CBOW mode)...\")\n",
    "            model = Word2Vec(vector_size=VECTOR_SIZE, \n",
    "                             window=WINDOW, \n",
    "                             min_count=MIN_COUNT, \n",
    "                             workers=WORKERS, \n",
    "                             sg=SG) \n",
    "            \n",
    "            print(\"   Building vocabulary...\")\n",
    "            model.build_vocab(corpus)\n",
    "            \n",
    "            print(f\"   Starting training ({EPOCHS} epochs)...\")\n",
    "            try:\n",
    "                model.train(corpus, total_examples=model.corpus_count, epochs=EPOCHS)\n",
    "                print(f\"Model training complete.\")\n",
    "            except Exception as e:\n",
    "                print(f\"Critical error during training: {e}\")\n",
    "                exit(1)\n",
    "\n",
    "            print(\"5. Calculating technological distance...\")\n",
    "            distances = []\n",
    "            \n",
    "            for index, row in df.iterrows():\n",
    "                gp_words = row['gp_tokens']\n",
    "                hist_words = row['history_tokens']\n",
    "                \n",
    "                # If either text is missing/empty, distance is NaN\n",
    "                if not gp_words or not hist_words:\n",
    "                    distances.append(np.nan)\n",
    "                    continue\n",
    "                \n",
    "                vec_gp = get_document_vector(gp_words, model)\n",
    "                vec_hist = get_document_vector(hist_words, model)\n",
    "                \n",
    "                dist = calculate_distance_optimized(vec_gp, vec_hist)\n",
    "                distances.append(dist)\n",
    "                \n",
    "            df['tech_distance'] = distances\n",
    "\n",
    "            # Save Full Version\n",
    "            df_full = df[['stkcd', 'date', 'gp_pat', 'ng_pat_history', 'tech_distance']]\n",
    "            print(f\"\\nSaving full version to: {output_path_full}\")\n",
    "            df_full.to_csv(output_path_full, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            # Save Clean Version\n",
    "            df_clean = df[['stkcd', 'date', 'tech_distance']]\n",
    "            print(f\"Saving clean version to: {output_path_clean}\")\n",
    "            df_clean.to_csv(output_path_clean, index=False, encoding='utf-8-sig')\n",
    "            \n",
    "            print(\"\\nAll success!\")\n",
    "            print(df_clean['tech_distance'].describe())\n",
    "\n",
    "    else:\n",
    "        print(f\"Error: File not found {input_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d40763-0df9-48e6-b780-8d0b18326e74",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
